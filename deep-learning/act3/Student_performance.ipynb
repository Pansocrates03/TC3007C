{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are a data scientist working for a school\n",
    "\n",
    "You are asked to predict the GPA of the current students based on the following provided data: \n",
    "\n",
    " 0   StudentID  int64  \n",
    " 1   Age    int64  \n",
    " 2   Gender int64  \n",
    " 3   Ethnicity  int64  \n",
    " 4   ParentalEducation  int64  \n",
    " 5   StudyTimeWeekly    float64\n",
    " 6   Absences   int64  \n",
    " 7   Tutoring   int64  \n",
    " 8   ParentalSupport    int64  \n",
    " 9   Extracurricular    int64  \n",
    " 10  Sports int64  \n",
    " 11  Music  int64  \n",
    " 12  Volunteering   int64  \n",
    " 13  GPA    float64\n",
    " 14  GradeClass float64\n",
    "\n",
    "The GPA is the Grade Point Average, typically ranges from 0.0 to 4.0 in most educational systems, with 4.0 representing an 'A' or excellent performance.\n",
    "\n",
    "The minimum passing GPA can vary by institution, but it's often around 2.0. This usually corresponds to a 'C' grade, which is considered satisfactory.\n",
    "\n",
    "You need to create a Deep Learning model capable to predict the GPA of a Student based on a set of provided features.\n",
    "The data provided represents 2,392 students.\n",
    "\n",
    "In this excersice you will be requested to create a total of three models and select the most performant one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries\n",
    "\n",
    "First let's import the following libraries, if there is any library that you need and is not in the list bellow feel free to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Data\n",
    "\n",
    "- You will be provided with a cvs (comma separated value) file.\n",
    "- You will need to add that file into a pandas dataframe, you can use the following code as reference\n",
    "- The file will be available in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0       1001   17       1          0                  2        19.833723   \n",
       "1       1002   18       0          0                  1        15.408756   \n",
       "2       1003   15       0          2                  3         4.210570   \n",
       "3       1004   17       1          0                  3        10.028829   \n",
       "4       1005   17       1          0                  2         4.672495   \n",
       "\n",
       "   Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0         7         1                2                0       0      1   \n",
       "1         0         0                1                0       0      0   \n",
       "2        26         0                2                0       0      0   \n",
       "3        14         0                3                1       0      0   \n",
       "4        17         1                3                0       0      0   \n",
       "\n",
       "   Volunteering       GPA  GradeClass  \n",
       "0             0  2.929196         2.0  \n",
       "1             0  3.042915         1.0  \n",
       "2             0  0.112602         4.0  \n",
       "3             0  2.054218         3.0  \n",
       "4             0  1.288061         4.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Student_performance_data _.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Review you data:\n",
    "\n",
    "Make sure you review your data.\n",
    "Place special attention of null or empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   StudentID          2392 non-null   int64  \n",
      " 1   Age                2392 non-null   int64  \n",
      " 2   Gender             2392 non-null   int64  \n",
      " 3   Ethnicity          2392 non-null   int64  \n",
      " 4   ParentalEducation  2392 non-null   int64  \n",
      " 5   StudyTimeWeekly    2392 non-null   float64\n",
      " 6   Absences           2392 non-null   int64  \n",
      " 7   Tutoring           2392 non-null   int64  \n",
      " 8   ParentalSupport    2392 non-null   int64  \n",
      " 9   Extracurricular    2392 non-null   int64  \n",
      " 10  Sports             2392 non-null   int64  \n",
      " 11  Music              2392 non-null   int64  \n",
      " 12  Volunteering       2392 non-null   int64  \n",
      " 13  GPA                2392 non-null   float64\n",
      " 14  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 280.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the columns not needed for Student performance prediction\n",
    "\n",
    "- Choose only the columns you consider to be valuable for your model training.\n",
    "- For example, StudentID might not be a good feature for your model, and thus should be removed from your main dataset, which other columns should also be removed?\n",
    "- You can name that final dataset as 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Age                2392 non-null   int64  \n",
      " 1   Gender             2392 non-null   int64  \n",
      " 2   Ethnicity          2392 non-null   int64  \n",
      " 3   ParentalEducation  2392 non-null   int64  \n",
      " 4   StudyTimeWeekly    2392 non-null   float64\n",
      " 5   Absences           2392 non-null   int64  \n",
      " 6   Tutoring           2392 non-null   int64  \n",
      " 7   ParentalSupport    2392 non-null   int64  \n",
      " 8   Extracurricular    2392 non-null   int64  \n",
      " 9   Sports             2392 non-null   int64  \n",
      " 10  Music              2392 non-null   int64  \n",
      " 11  Volunteering       2392 non-null   int64  \n",
      " 12  GPA                2392 non-null   float64\n",
      " 13  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 261.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Remove StudentID column\n",
    "data = data.drop(columns=['StudentID'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check if the columns has any null values:\n",
    "- Here you now have your final dataset to use in your model training.\n",
    "- Before moving foward review your data check for any null or empty value that might be needed to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                  0\n",
      "Gender               0\n",
      "Ethnicity            0\n",
      "ParentalEducation    0\n",
      "StudyTimeWeekly      0\n",
      "Absences             0\n",
      "Tutoring             0\n",
      "ParentalSupport      0\n",
      "Extracurricular      0\n",
      "Sports               0\n",
      "Music                0\n",
      "Volunteering         0\n",
      "GPA                  0\n",
      "GradeClass           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare your data for training and for testing set:\n",
    " - First create a dataset named X, with all columns but GPA. These are the features\n",
    " - Next create another dataset named y, with only GPA column. This is the label\n",
    " - If you go to your Imports, you will see the following import: **'from sklearn.model_selection import train_test_split'**\n",
    " - Use that *train_test_split* function to create: X_train, X_test, y_train and y_test respectively. Use X and y datasets as parameters. Other parameters to use are: Test Size = 0.2, Random State = 42.\n",
    " \n",
    " - Standarize your features (X_train and X_test) by using the StandardScaler (investigate how to use fit_transform and transform functions). This will help the training process by dealing with normilized data.\n",
    "\n",
    " Note: Your X_train shape should be around (1913, 10). This means the dataset has 10 columns which should be the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1913, 13) x_test shape: (479, 13)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "x = data.drop(columns=['GPA'])\n",
    "y = data['GPA']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# Scale features using StandardScaler (fit on train, transform on test)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "print('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define your Deep Neural Network.\n",
    "- This will be a Sequential Neural Network.\n",
    "- With a Dense input layer with 64 units, and input dimention of 10 and Relu as the activation function.\n",
    "- A Dense hidden layer with 32 units, and Relu as the activation function.\n",
    "- And a Dense output layer with 1 unit, do not define an activation function so it defaults to linear, suitable for regression tasks. e.g. Dense(1)\n",
    "\n",
    "This last part of the output layer is super important, since we want to predict the GPA, this means that we want a regression and not a classification. Linear activation function is best for regression and Sigmoid is best for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "model = Sequential()\n",
    "# Use the number of features from x_train for the input shape\n",
    "model.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # linear output for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile your Neural Network\n",
    "- Choose Adam as the optimizer\n",
    "- And MSE as the Loss function\n",
    "- Also add the following metrics: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# For regression use MSE loss and track MAE as a metric\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit (or train) your model\n",
    "- Use the X_train and y_train datasets for the training\n",
    "- Do 50 data iterations\n",
    "- Choose the batch size = 10\n",
    "- Also select a validation_split of 0.2\n",
    "- Save the result of the fit function in a variable called 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.1096 - mae: 0.7417 - val_loss: 0.1493 - val_mae: 0.3119\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.1096 - mae: 0.7417 - val_loss: 0.1493 - val_mae: 0.3119\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1040 - mae: 0.2573 - val_loss: 0.0949 - val_mae: 0.2516\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1040 - mae: 0.2573 - val_loss: 0.0949 - val_mae: 0.2516\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0698 - mae: 0.2132 - val_loss: 0.0749 - val_mae: 0.2238\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0698 - mae: 0.2132 - val_loss: 0.0749 - val_mae: 0.2238\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0567 - mae: 0.1912 - val_loss: 0.0723 - val_mae: 0.2169\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0567 - mae: 0.1912 - val_loss: 0.0723 - val_mae: 0.2169\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0494 - mae: 0.1796 - val_loss: 0.0602 - val_mae: 0.1984\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0494 - mae: 0.1796 - val_loss: 0.0602 - val_mae: 0.1984\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0439 - mae: 0.1696 - val_loss: 0.0565 - val_mae: 0.1912\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0439 - mae: 0.1696 - val_loss: 0.0565 - val_mae: 0.1912\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0405 - mae: 0.1625 - val_loss: 0.0520 - val_mae: 0.1837\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0405 - mae: 0.1625 - val_loss: 0.0520 - val_mae: 0.1837\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - mae: 0.1576 - val_loss: 0.0531 - val_mae: 0.1845\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - mae: 0.1576 - val_loss: 0.0531 - val_mae: 0.1845\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.1524 - val_loss: 0.0543 - val_mae: 0.1864\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0361 - mae: 0.1524 - val_loss: 0.0543 - val_mae: 0.1864\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.1489 - val_loss: 0.0503 - val_mae: 0.1801\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.1489 - val_loss: 0.0503 - val_mae: 0.1801\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - mae: 0.1456 - val_loss: 0.0505 - val_mae: 0.1797\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - mae: 0.1456 - val_loss: 0.0505 - val_mae: 0.1797\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.1433 - val_loss: 0.0504 - val_mae: 0.1770\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - mae: 0.1433 - val_loss: 0.0504 - val_mae: 0.1770\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - mae: 0.1387 - val_loss: 0.0495 - val_mae: 0.1770\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - mae: 0.1387 - val_loss: 0.0495 - val_mae: 0.1770\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.1349 - val_loss: 0.0484 - val_mae: 0.1772\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.1349 - val_loss: 0.0484 - val_mae: 0.1772\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1338 - val_loss: 0.0498 - val_mae: 0.1768\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1338 - val_loss: 0.0498 - val_mae: 0.1768\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1313 - val_loss: 0.0464 - val_mae: 0.1723\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1313 - val_loss: 0.0464 - val_mae: 0.1723\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - mae: 0.1324 - val_loss: 0.0486 - val_mae: 0.1770\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - mae: 0.1324 - val_loss: 0.0486 - val_mae: 0.1770\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - mae: 0.1307 - val_loss: 0.0455 - val_mae: 0.1711\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - mae: 0.1307 - val_loss: 0.0455 - val_mae: 0.1711\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.1252 - val_loss: 0.0479 - val_mae: 0.1742\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.1252 - val_loss: 0.0479 - val_mae: 0.1742\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.1257 - val_loss: 0.0469 - val_mae: 0.1734\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.1257 - val_loss: 0.0469 - val_mae: 0.1734\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1249 - val_loss: 0.0478 - val_mae: 0.1756\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1249 - val_loss: 0.0478 - val_mae: 0.1756\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.1230 - val_loss: 0.0469 - val_mae: 0.1736\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.1230 - val_loss: 0.0469 - val_mae: 0.1736\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.1191 - val_loss: 0.0519 - val_mae: 0.1831\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.1191 - val_loss: 0.0519 - val_mae: 0.1831\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0225 - mae: 0.1190 - val_loss: 0.0458 - val_mae: 0.1690\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0225 - mae: 0.1190 - val_loss: 0.0458 - val_mae: 0.1690\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0219 - mae: 0.1175 - val_loss: 0.0446 - val_mae: 0.1686\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0219 - mae: 0.1175 - val_loss: 0.0446 - val_mae: 0.1686\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0214 - mae: 0.1162 - val_loss: 0.0471 - val_mae: 0.1725\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0214 - mae: 0.1162 - val_loss: 0.0471 - val_mae: 0.1725\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1147 - val_loss: 0.0460 - val_mae: 0.1701\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1147 - val_loss: 0.0460 - val_mae: 0.1701\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.1144 - val_loss: 0.0473 - val_mae: 0.1698\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.1144 - val_loss: 0.0473 - val_mae: 0.1698\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - mae: 0.1121 - val_loss: 0.0520 - val_mae: 0.1822\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - mae: 0.1121 - val_loss: 0.0520 - val_mae: 0.1822\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.1127 - val_loss: 0.0472 - val_mae: 0.1736\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - mae: 0.1127 - val_loss: 0.0472 - val_mae: 0.1736\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186 - mae: 0.1088 - val_loss: 0.0522 - val_mae: 0.1791\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186 - mae: 0.1088 - val_loss: 0.0522 - val_mae: 0.1791\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192 - mae: 0.1097 - val_loss: 0.0485 - val_mae: 0.1746\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192 - mae: 0.1097 - val_loss: 0.0485 - val_mae: 0.1746\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.1072 - val_loss: 0.0499 - val_mae: 0.1811\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - mae: 0.1072 - val_loss: 0.0499 - val_mae: 0.1811\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177 - mae: 0.1045 - val_loss: 0.0509 - val_mae: 0.1775\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177 - mae: 0.1045 - val_loss: 0.0509 - val_mae: 0.1775\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176 - mae: 0.1048 - val_loss: 0.0482 - val_mae: 0.1739\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176 - mae: 0.1048 - val_loss: 0.0482 - val_mae: 0.1739\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mae: 0.1032 - val_loss: 0.0479 - val_mae: 0.1740\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170 - mae: 0.1032 - val_loss: 0.0479 - val_mae: 0.1740\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.1081 - val_loss: 0.0495 - val_mae: 0.1790\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.1081 - val_loss: 0.0495 - val_mae: 0.1790\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mae: 0.1022 - val_loss: 0.0561 - val_mae: 0.1849\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167 - mae: 0.1022 - val_loss: 0.0561 - val_mae: 0.1849\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0988 - val_loss: 0.0500 - val_mae: 0.1779\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0988 - val_loss: 0.0500 - val_mae: 0.1779\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0978 - val_loss: 0.0498 - val_mae: 0.1757\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0978 - val_loss: 0.0498 - val_mae: 0.1757\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0146 - mae: 0.0957 - val_loss: 0.0534 - val_mae: 0.1822\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0146 - mae: 0.0957 - val_loss: 0.0534 - val_mae: 0.1822\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mae: 0.0978 - val_loss: 0.0521 - val_mae: 0.1804\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0150 - mae: 0.0978 - val_loss: 0.0521 - val_mae: 0.1804\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0975 - val_loss: 0.0528 - val_mae: 0.1812\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0975 - val_loss: 0.0528 - val_mae: 0.1812\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0955 - val_loss: 0.0510 - val_mae: 0.1752\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0955 - val_loss: 0.0510 - val_mae: 0.1752\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0905 - val_loss: 0.0508 - val_mae: 0.1777\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0134 - mae: 0.0905 - val_loss: 0.0508 - val_mae: 0.1777\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0942 - val_loss: 0.0549 - val_mae: 0.1873\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0942 - val_loss: 0.0549 - val_mae: 0.1873\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0954 - val_loss: 0.0566 - val_mae: 0.1877\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0954 - val_loss: 0.0566 - val_mae: 0.1877\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0948 - val_loss: 0.0586 - val_mae: 0.1906\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0948 - val_loss: 0.0586 - val_mae: 0.1906\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0930 - val_loss: 0.0515 - val_mae: 0.1783\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0930 - val_loss: 0.0515 - val_mae: 0.1783\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0911 - val_loss: 0.0534 - val_mae: 0.1808\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0911 - val_loss: 0.0534 - val_mae: 0.1808\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# fit the keras model on the dataset\n",
    "# Use a validation split and store the history\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. View your history variable:\n",
    "- Use Matplotlib.pyplot to show graphs of your model traning history\n",
    "- In one graph:\n",
    "   - Plot the Training Loss and the Validation Loss\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Loss\n",
    "   - Title = Training and Validation Loss over Epochs\n",
    "- In a second graph:\n",
    "   - Plot the Training MAE and the Validation MAE\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Mean Absolute Error (MAE)\n",
    "   - Title = Training and Validation MAE over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c805feed50>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matplotlib code to show graphs of model training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your model:\n",
    "- See the result of your loss function.\n",
    "- What can you deduct from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Result of loss function\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.legend([\"Training MAE\", \"Validation MAE\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use your model to make some predictions:\n",
    "- Make predictions of your X_test dataset\n",
    "- Print the each of the predictions and the actual value (which is in y_test)\n",
    "- How good was your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Test MSE: 0.05553159080897823, Test MAE: 0.1814346866158936\n",
      "Test MSE: 0.05553159080897823, Test MAE: 0.1814346866158936\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Compete against this model:\n",
    "- Create two more different models to compete with this model\n",
    "- Here are a few ideas of things you can change:\n",
    "   - During Dataset data engineering:\n",
    "      - You can remove features that you think do not help in the training and prediction \n",
    "      - Feature Scaling: Ensure all features are on a similar scale (as you already did with StandardScaler)\n",
    "   - During Model Definition:\n",
    "      - You can change the Model Architecture (change the type or number of layers or the number of units)\n",
    "      - You can add dropout layers to prevent overfitting\n",
    "   - During Model Compile:\n",
    "      - You can try other optimizer when compiling your model, here some optimizer samples: Adam, RMSprop, or Adagrad.\n",
    "      - Try another Loss Function\n",
    "   - During Model Training:\n",
    "      - Encrease the number of Epochs\n",
    "      - Adjust the size of your batch\n",
    "- Explain in a Markdown cell which changes are you implementing\n",
    "- Show the comparison of your model versus the original model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering\n",
    "   - Model Definition\n",
    "   - Model Compile\n",
    "   - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.6743 - mae: 0.5546 - val_loss: 0.3671 - val_mae: 0.3881\n",
      "Epoch 2/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.6743 - mae: 0.5546 - val_loss: 0.3671 - val_mae: 0.3881\n",
      "Epoch 2/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3908 - mae: 0.3907 - val_loss: 0.3115 - val_mae: 0.3466\n",
      "Epoch 3/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3908 - mae: 0.3907 - val_loss: 0.3115 - val_mae: 0.3466\n",
      "Epoch 3/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3076 - mae: 0.3247 - val_loss: 0.2624 - val_mae: 0.3009\n",
      "Epoch 4/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.3076 - mae: 0.3247 - val_loss: 0.2624 - val_mae: 0.3009\n",
      "Epoch 4/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2770 - mae: 0.3003 - val_loss: 0.3260 - val_mae: 0.3781\n",
      "Epoch 5/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2770 - mae: 0.3003 - val_loss: 0.3260 - val_mae: 0.3781\n",
      "Epoch 5/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2530 - mae: 0.2796 - val_loss: 0.2428 - val_mae: 0.2876\n",
      "Epoch 6/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2530 - mae: 0.2796 - val_loss: 0.2428 - val_mae: 0.2876\n",
      "Epoch 6/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2322 - mae: 0.2689 - val_loss: 0.3009 - val_mae: 0.3658\n",
      "Epoch 7/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2322 - mae: 0.2689 - val_loss: 0.3009 - val_mae: 0.3658\n",
      "Epoch 7/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2146 - mae: 0.2568 - val_loss: 0.1879 - val_mae: 0.2311\n",
      "Epoch 8/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2146 - mae: 0.2568 - val_loss: 0.1879 - val_mae: 0.2311\n",
      "Epoch 8/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1960 - mae: 0.2386 - val_loss: 0.2085 - val_mae: 0.2709\n",
      "Epoch 9/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1960 - mae: 0.2386 - val_loss: 0.2085 - val_mae: 0.2709\n",
      "Epoch 9/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1815 - mae: 0.2264 - val_loss: 0.1649 - val_mae: 0.2142\n",
      "Epoch 10/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1815 - mae: 0.2264 - val_loss: 0.1649 - val_mae: 0.2142\n",
      "Epoch 10/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1667 - mae: 0.2156 - val_loss: 0.1548 - val_mae: 0.2056\n",
      "Epoch 11/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1667 - mae: 0.2156 - val_loss: 0.1548 - val_mae: 0.2056\n",
      "Epoch 11/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1588 - mae: 0.2118 - val_loss: 0.1365 - val_mae: 0.1794\n",
      "Epoch 12/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1588 - mae: 0.2118 - val_loss: 0.1365 - val_mae: 0.1794\n",
      "Epoch 12/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1539 - mae: 0.2051 - val_loss: 0.1254 - val_mae: 0.1686\n",
      "Epoch 13/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1539 - mae: 0.2051 - val_loss: 0.1254 - val_mae: 0.1686\n",
      "Epoch 13/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1502 - mae: 0.2104 - val_loss: 0.1669 - val_mae: 0.2513\n",
      "Epoch 14/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1502 - mae: 0.2104 - val_loss: 0.1669 - val_mae: 0.2513\n",
      "Epoch 14/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1397 - mae: 0.2031 - val_loss: 0.1695 - val_mae: 0.2558\n",
      "Epoch 15/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1397 - mae: 0.2031 - val_loss: 0.1695 - val_mae: 0.2558\n",
      "Epoch 15/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1325 - mae: 0.1963 - val_loss: 0.1168 - val_mae: 0.1766\n",
      "Epoch 16/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1325 - mae: 0.1963 - val_loss: 0.1168 - val_mae: 0.1766\n",
      "Epoch 16/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1292 - mae: 0.1961 - val_loss: 0.1543 - val_mae: 0.2469\n",
      "Epoch 17/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1292 - mae: 0.1961 - val_loss: 0.1543 - val_mae: 0.2469\n",
      "Epoch 17/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.1987 - val_loss: 0.1144 - val_mae: 0.1884\n",
      "Epoch 18/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1246 - mae: 0.1987 - val_loss: 0.1144 - val_mae: 0.1884\n",
      "Epoch 18/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1163 - mae: 0.1929 - val_loss: 0.1169 - val_mae: 0.1996\n",
      "Epoch 19/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1163 - mae: 0.1929 - val_loss: 0.1169 - val_mae: 0.1996\n",
      "Epoch 19/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1143 - mae: 0.1907 - val_loss: 0.0925 - val_mae: 0.1552\n",
      "Epoch 20/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1143 - mae: 0.1907 - val_loss: 0.0925 - val_mae: 0.1552\n",
      "Epoch 20/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1062 - mae: 0.1822 - val_loss: 0.0872 - val_mae: 0.1514\n",
      "Epoch 21/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1062 - mae: 0.1822 - val_loss: 0.0872 - val_mae: 0.1514\n",
      "Epoch 21/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1023 - mae: 0.1832 - val_loss: 0.1126 - val_mae: 0.2078\n",
      "Epoch 22/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1023 - mae: 0.1832 - val_loss: 0.1126 - val_mae: 0.2078\n",
      "Epoch 22/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1001 - mae: 0.1822 - val_loss: 0.0962 - val_mae: 0.1858\n",
      "Epoch 23/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1001 - mae: 0.1822 - val_loss: 0.0962 - val_mae: 0.1858\n",
      "Epoch 23/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0920 - mae: 0.1752 - val_loss: 0.0776 - val_mae: 0.1475\n",
      "Epoch 24/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0920 - mae: 0.1752 - val_loss: 0.0776 - val_mae: 0.1475\n",
      "Epoch 24/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0895 - mae: 0.1768 - val_loss: 0.0983 - val_mae: 0.1989\n",
      "Epoch 25/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0895 - mae: 0.1768 - val_loss: 0.0983 - val_mae: 0.1989\n",
      "Epoch 25/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0900 - mae: 0.1814 - val_loss: 0.0884 - val_mae: 0.1810\n",
      "Epoch 26/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0900 - mae: 0.1814 - val_loss: 0.0884 - val_mae: 0.1810\n",
      "Epoch 26/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0827 - mae: 0.1689 - val_loss: 0.0733 - val_mae: 0.1531\n",
      "Epoch 27/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0827 - mae: 0.1689 - val_loss: 0.0733 - val_mae: 0.1531\n",
      "Epoch 27/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0832 - mae: 0.1762 - val_loss: 0.0704 - val_mae: 0.1549\n",
      "Epoch 28/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0832 - mae: 0.1762 - val_loss: 0.0704 - val_mae: 0.1549\n",
      "Epoch 28/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0800 - mae: 0.1733 - val_loss: 0.0707 - val_mae: 0.1524\n",
      "Epoch 29/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0800 - mae: 0.1733 - val_loss: 0.0707 - val_mae: 0.1524\n",
      "Epoch 29/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0804 - mae: 0.1732 - val_loss: 0.0697 - val_mae: 0.1596\n",
      "Epoch 30/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0804 - mae: 0.1732 - val_loss: 0.0697 - val_mae: 0.1596\n",
      "Epoch 30/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0755 - mae: 0.1687 - val_loss: 0.0683 - val_mae: 0.1566\n",
      "Epoch 31/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0755 - mae: 0.1687 - val_loss: 0.0683 - val_mae: 0.1566\n",
      "Epoch 31/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0782 - mae: 0.1758 - val_loss: 0.0756 - val_mae: 0.1730\n",
      "Epoch 32/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0782 - mae: 0.1758 - val_loss: 0.0756 - val_mae: 0.1730\n",
      "Epoch 32/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0744 - mae: 0.1711 - val_loss: 0.0668 - val_mae: 0.1593\n",
      "Epoch 33/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0744 - mae: 0.1711 - val_loss: 0.0668 - val_mae: 0.1593\n",
      "Epoch 33/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.1732 - val_loss: 0.0746 - val_mae: 0.1805\n",
      "Epoch 34/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0728 - mae: 0.1732 - val_loss: 0.0746 - val_mae: 0.1805\n",
      "Epoch 34/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0693 - mae: 0.1681 - val_loss: 0.0797 - val_mae: 0.1898\n",
      "Epoch 35/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0693 - mae: 0.1681 - val_loss: 0.0797 - val_mae: 0.1898\n",
      "Epoch 35/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0707 - mae: 0.1724 - val_loss: 0.0682 - val_mae: 0.1680\n",
      "Epoch 36/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0707 - mae: 0.1724 - val_loss: 0.0682 - val_mae: 0.1680\n",
      "Epoch 36/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0732 - mae: 0.1778 - val_loss: 0.0612 - val_mae: 0.1532\n",
      "Epoch 37/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0732 - mae: 0.1778 - val_loss: 0.0612 - val_mae: 0.1532\n",
      "Epoch 37/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0664 - mae: 0.1672 - val_loss: 0.0737 - val_mae: 0.1832\n",
      "Epoch 38/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0664 - mae: 0.1672 - val_loss: 0.0737 - val_mae: 0.1832\n",
      "Epoch 38/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0659 - mae: 0.1645 - val_loss: 0.0671 - val_mae: 0.1669\n",
      "Epoch 39/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0659 - mae: 0.1645 - val_loss: 0.0671 - val_mae: 0.1669\n",
      "Epoch 39/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0622 - mae: 0.1612 - val_loss: 0.0720 - val_mae: 0.1840\n",
      "Epoch 40/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0622 - mae: 0.1612 - val_loss: 0.0720 - val_mae: 0.1840\n",
      "Epoch 40/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0616 - mae: 0.1614 - val_loss: 0.0685 - val_mae: 0.1738\n",
      "Epoch 41/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0616 - mae: 0.1614 - val_loss: 0.0685 - val_mae: 0.1738\n",
      "Epoch 41/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0626 - mae: 0.1630 - val_loss: 0.0616 - val_mae: 0.1595\n",
      "Epoch 42/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0626 - mae: 0.1630 - val_loss: 0.0616 - val_mae: 0.1595\n",
      "Epoch 42/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0610 - mae: 0.1612 - val_loss: 0.0587 - val_mae: 0.1572\n",
      "Epoch 43/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0610 - mae: 0.1612 - val_loss: 0.0587 - val_mae: 0.1572\n",
      "Epoch 43/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0614 - mae: 0.1640 - val_loss: 0.0731 - val_mae: 0.1843\n",
      "Epoch 44/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0614 - mae: 0.1640 - val_loss: 0.0731 - val_mae: 0.1843\n",
      "Epoch 44/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0598 - mae: 0.1600 - val_loss: 0.0638 - val_mae: 0.1627\n",
      "Epoch 45/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0598 - mae: 0.1600 - val_loss: 0.0638 - val_mae: 0.1627\n",
      "Epoch 45/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.1613 - val_loss: 0.0557 - val_mae: 0.1535\n",
      "Epoch 46/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.1613 - val_loss: 0.0557 - val_mae: 0.1535\n",
      "Epoch 46/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0569 - mae: 0.1567 - val_loss: 0.0576 - val_mae: 0.1562\n",
      "Epoch 47/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0569 - mae: 0.1567 - val_loss: 0.0576 - val_mae: 0.1562\n",
      "Epoch 47/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0578 - mae: 0.1586 - val_loss: 0.0761 - val_mae: 0.1979\n",
      "Epoch 48/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0578 - mae: 0.1586 - val_loss: 0.0761 - val_mae: 0.1979\n",
      "Epoch 48/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0619 - mae: 0.1676 - val_loss: 0.0537 - val_mae: 0.1494\n",
      "Epoch 49/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0619 - mae: 0.1676 - val_loss: 0.0537 - val_mae: 0.1494\n",
      "Epoch 49/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0564 - mae: 0.1577 - val_loss: 0.0618 - val_mae: 0.1646\n",
      "Epoch 50/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0564 - mae: 0.1577 - val_loss: 0.0618 - val_mae: 0.1646\n",
      "Epoch 50/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0580 - mae: 0.1602 - val_loss: 0.0631 - val_mae: 0.1657\n",
      "Epoch 51/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0580 - mae: 0.1602 - val_loss: 0.0631 - val_mae: 0.1657\n",
      "Epoch 51/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0543 - mae: 0.1544 - val_loss: 0.0732 - val_mae: 0.1878\n",
      "Epoch 52/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0543 - mae: 0.1544 - val_loss: 0.0732 - val_mae: 0.1878\n",
      "Epoch 52/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0547 - mae: 0.1544 - val_loss: 0.0552 - val_mae: 0.1547\n",
      "Epoch 53/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0547 - mae: 0.1544 - val_loss: 0.0552 - val_mae: 0.1547\n",
      "Epoch 53/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0573 - mae: 0.1616 - val_loss: 0.0739 - val_mae: 0.1983\n",
      "Epoch 54/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0573 - mae: 0.1616 - val_loss: 0.0739 - val_mae: 0.1983\n",
      "Epoch 54/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0547 - mae: 0.1571 - val_loss: 0.0687 - val_mae: 0.1850\n",
      "Epoch 55/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0547 - mae: 0.1571 - val_loss: 0.0687 - val_mae: 0.1850\n",
      "Epoch 55/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.1613 - val_loss: 0.0634 - val_mae: 0.1717\n",
      "Epoch 56/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0585 - mae: 0.1613 - val_loss: 0.0634 - val_mae: 0.1717\n",
      "Epoch 56/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0563 - mae: 0.1596 - val_loss: 0.0578 - val_mae: 0.1607\n",
      "Epoch 57/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0563 - mae: 0.1596 - val_loss: 0.0578 - val_mae: 0.1607\n",
      "Epoch 57/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.1574 - val_loss: 0.0627 - val_mae: 0.1744\n",
      "Epoch 58/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.1574 - val_loss: 0.0627 - val_mae: 0.1744\n",
      "Epoch 58/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0515 - mae: 0.1509 - val_loss: 0.0559 - val_mae: 0.1575\n",
      "Epoch 59/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0515 - mae: 0.1509 - val_loss: 0.0559 - val_mae: 0.1575\n",
      "Epoch 59/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0551 - mae: 0.1583 - val_loss: 0.0613 - val_mae: 0.1673\n",
      "Epoch 60/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0551 - mae: 0.1583 - val_loss: 0.0613 - val_mae: 0.1673\n",
      "Epoch 60/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0542 - mae: 0.1565 - val_loss: 0.0586 - val_mae: 0.1609\n",
      "Epoch 61/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0542 - mae: 0.1565 - val_loss: 0.0586 - val_mae: 0.1609\n",
      "Epoch 61/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0540 - mae: 0.1586 - val_loss: 0.0866 - val_mae: 0.2215\n",
      "Epoch 62/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0540 - mae: 0.1586 - val_loss: 0.0866 - val_mae: 0.2215\n",
      "Epoch 62/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0536 - mae: 0.1561 - val_loss: 0.0705 - val_mae: 0.1862\n",
      "Epoch 63/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0536 - mae: 0.1561 - val_loss: 0.0705 - val_mae: 0.1862\n",
      "Epoch 63/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0556 - mae: 0.1586 - val_loss: 0.0838 - val_mae: 0.2118\n",
      "Epoch 64/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0556 - mae: 0.1586 - val_loss: 0.0838 - val_mae: 0.2118\n",
      "Epoch 64/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0552 - mae: 0.1583 - val_loss: 0.0822 - val_mae: 0.2060\n",
      "Epoch 65/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0552 - mae: 0.1583 - val_loss: 0.0822 - val_mae: 0.2060\n",
      "Epoch 65/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0523 - mae: 0.1530 - val_loss: 0.0700 - val_mae: 0.1884\n",
      "Epoch 66/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0523 - mae: 0.1530 - val_loss: 0.0700 - val_mae: 0.1884\n",
      "Epoch 66/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0529 - mae: 0.1548 - val_loss: 0.0676 - val_mae: 0.1871\n",
      "Epoch 67/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0529 - mae: 0.1548 - val_loss: 0.0676 - val_mae: 0.1871\n",
      "Epoch 67/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0539 - mae: 0.1560 - val_loss: 0.0639 - val_mae: 0.1784\n",
      "Epoch 68/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0539 - mae: 0.1560 - val_loss: 0.0639 - val_mae: 0.1784\n",
      "Epoch 68/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.1593 - val_loss: 0.0734 - val_mae: 0.1919\n",
      "Epoch 69/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.1593 - val_loss: 0.0734 - val_mae: 0.1919\n",
      "Epoch 69/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0531 - mae: 0.1557 - val_loss: 0.0685 - val_mae: 0.1848\n",
      "Epoch 70/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0531 - mae: 0.1557 - val_loss: 0.0685 - val_mae: 0.1848\n",
      "Epoch 70/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0534 - mae: 0.1562 - val_loss: 0.0546 - val_mae: 0.1581\n",
      "Epoch 71/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0534 - mae: 0.1562 - val_loss: 0.0546 - val_mae: 0.1581\n",
      "Epoch 71/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.1521 - val_loss: 0.0788 - val_mae: 0.2050\n",
      "Epoch 72/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.1521 - val_loss: 0.0788 - val_mae: 0.2050\n",
      "Epoch 72/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0543 - mae: 0.1597 - val_loss: 0.0729 - val_mae: 0.1949\n",
      "Epoch 73/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0543 - mae: 0.1597 - val_loss: 0.0729 - val_mae: 0.1949\n",
      "Epoch 73/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.1561 - val_loss: 0.0711 - val_mae: 0.1883\n",
      "Epoch 74/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.1561 - val_loss: 0.0711 - val_mae: 0.1883\n",
      "Epoch 74/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0533 - mae: 0.1563 - val_loss: 0.0602 - val_mae: 0.1709\n",
      "Epoch 75/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0533 - mae: 0.1563 - val_loss: 0.0602 - val_mae: 0.1709\n",
      "Epoch 75/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1559 - val_loss: 0.0832 - val_mae: 0.2138\n",
      "Epoch 76/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1559 - val_loss: 0.0832 - val_mae: 0.2138\n",
      "Epoch 76/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0515 - mae: 0.1534 - val_loss: 0.0728 - val_mae: 0.1980\n",
      "Epoch 77/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0515 - mae: 0.1534 - val_loss: 0.0728 - val_mae: 0.1980\n",
      "Epoch 77/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0541 - mae: 0.1586 - val_loss: 0.0609 - val_mae: 0.1703\n",
      "Epoch 78/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0541 - mae: 0.1586 - val_loss: 0.0609 - val_mae: 0.1703\n",
      "Epoch 78/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0552 - mae: 0.1618 - val_loss: 0.0683 - val_mae: 0.1867\n",
      "Epoch 79/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0552 - mae: 0.1618 - val_loss: 0.0683 - val_mae: 0.1867\n",
      "Epoch 79/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0514 - mae: 0.1550 - val_loss: 0.0813 - val_mae: 0.2106\n",
      "Epoch 80/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0514 - mae: 0.1550 - val_loss: 0.0813 - val_mae: 0.2106\n",
      "Epoch 80/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0514 - mae: 0.1533 - val_loss: 0.0620 - val_mae: 0.1733\n",
      "Epoch 81/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0514 - mae: 0.1533 - val_loss: 0.0620 - val_mae: 0.1733\n",
      "Epoch 81/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.1572 - val_loss: 0.0982 - val_mae: 0.2369\n",
      "Epoch 82/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0528 - mae: 0.1572 - val_loss: 0.0982 - val_mae: 0.2369\n",
      "Epoch 82/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0510 - mae: 0.1527 - val_loss: 0.0666 - val_mae: 0.1767\n",
      "Epoch 83/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0510 - mae: 0.1527 - val_loss: 0.0666 - val_mae: 0.1767\n",
      "Epoch 83/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.1576 - val_loss: 0.0929 - val_mae: 0.2296\n",
      "Epoch 84/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.1576 - val_loss: 0.0929 - val_mae: 0.2296\n",
      "Epoch 84/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0568 - mae: 0.1634 - val_loss: 0.0727 - val_mae: 0.1919\n",
      "Epoch 85/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0568 - mae: 0.1634 - val_loss: 0.0727 - val_mae: 0.1919\n",
      "Epoch 85/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.1525 - val_loss: 0.0611 - val_mae: 0.1714\n",
      "Epoch 86/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.1525 - val_loss: 0.0611 - val_mae: 0.1714\n",
      "Epoch 86/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1569 - val_loss: 0.0999 - val_mae: 0.2413\n",
      "Epoch 87/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1569 - val_loss: 0.0999 - val_mae: 0.2413\n",
      "Epoch 87/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0537 - mae: 0.1560 - val_loss: 0.0707 - val_mae: 0.1956\n",
      "Epoch 88/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0537 - mae: 0.1560 - val_loss: 0.0707 - val_mae: 0.1956\n",
      "Epoch 88/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.1545 - val_loss: 0.0585 - val_mae: 0.1693\n",
      "Epoch 89/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0508 - mae: 0.1545 - val_loss: 0.0585 - val_mae: 0.1693\n",
      "Epoch 89/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.1558 - val_loss: 0.0980 - val_mae: 0.2340\n",
      "Epoch 90/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.1558 - val_loss: 0.0980 - val_mae: 0.2340\n",
      "Epoch 90/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0526 - mae: 0.1554 - val_loss: 0.0786 - val_mae: 0.2052\n",
      "Epoch 91/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0526 - mae: 0.1554 - val_loss: 0.0786 - val_mae: 0.2052\n",
      "Epoch 91/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0496 - mae: 0.1499 - val_loss: 0.0603 - val_mae: 0.1691\n",
      "Epoch 92/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0496 - mae: 0.1499 - val_loss: 0.0603 - val_mae: 0.1691\n",
      "Epoch 92/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0518 - mae: 0.1542 - val_loss: 0.0887 - val_mae: 0.2179\n",
      "Epoch 93/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0518 - mae: 0.1542 - val_loss: 0.0887 - val_mae: 0.2179\n",
      "Epoch 93/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0520 - mae: 0.1549 - val_loss: 0.0681 - val_mae: 0.1824\n",
      "Epoch 94/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0520 - mae: 0.1549 - val_loss: 0.0681 - val_mae: 0.1824\n",
      "Epoch 94/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1560 - val_loss: 0.0810 - val_mae: 0.2094\n",
      "Epoch 95/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0529 - mae: 0.1560 - val_loss: 0.0810 - val_mae: 0.2094\n",
      "Epoch 95/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0535 - mae: 0.1595 - val_loss: 0.0888 - val_mae: 0.2245\n",
      "Epoch 96/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0535 - mae: 0.1595 - val_loss: 0.0888 - val_mae: 0.2245\n",
      "Epoch 96/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0522 - mae: 0.1578 - val_loss: 0.0708 - val_mae: 0.1890\n",
      "Epoch 97/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0522 - mae: 0.1578 - val_loss: 0.0708 - val_mae: 0.1890\n",
      "Epoch 97/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0504 - mae: 0.1524 - val_loss: 0.0755 - val_mae: 0.1991\n",
      "Epoch 98/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0504 - mae: 0.1524 - val_loss: 0.0755 - val_mae: 0.1991\n",
      "Epoch 98/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0520 - mae: 0.1565 - val_loss: 0.0689 - val_mae: 0.1829\n",
      "Epoch 99/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0520 - mae: 0.1565 - val_loss: 0.0689 - val_mae: 0.1829\n",
      "Epoch 99/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.1524 - val_loss: 0.0542 - val_mae: 0.1563\n",
      "Epoch 100/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0502 - mae: 0.1524 - val_loss: 0.0542 - val_mae: 0.1563\n",
      "Epoch 100/100\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0501 - mae: 0.1530 - val_loss: 0.0679 - val_mae: 0.1845\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0501 - mae: 0.1530 - val_loss: 0.0679 - val_mae: 0.1845\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Test MSE: 0.05294810358332716, Test MAE: 0.18103118290938466\n",
      "Test MSE: 0.05294810358332716, Test MAE: 0.18103118290938466\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_shape=(x_train.shape[1],), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(Dropout(0.3))\n",
    "model2.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model2.add(Dense(1))  # linear output for regression\n",
    "\n",
    "# Compile the second model\n",
    "model2.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Fit the second model\n",
    "history2 = model2.fit(x_train, y_train, epochs=100, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model2.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar tests al modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Test MSE: 0.05294810358332716, Test MAE: 0.18103118290938466\n",
      "Test MSE: 0.05294810358332716, Test MAE: 0.18103118290938466\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate the model\n",
    "y_pred = model2.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3:\n",
    "- Changes:\n",
    "   - Dataset Data Engineering\n",
    "   - Model Definition\n",
    "   - Model Compile\n",
    "   - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.4360 - mae: 0.4902 - val_loss: 0.1589 - val_mae: 0.3194\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.4360 - mae: 0.4902 - val_loss: 0.1589 - val_mae: 0.3194\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1256 - mae: 0.2801 - val_loss: 0.1053 - val_mae: 0.2589\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1256 - mae: 0.2801 - val_loss: 0.1053 - val_mae: 0.2589\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0965 - mae: 0.2470 - val_loss: 0.0968 - val_mae: 0.2454\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0965 - mae: 0.2470 - val_loss: 0.0968 - val_mae: 0.2454\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0832 - mae: 0.2286 - val_loss: 0.0824 - val_mae: 0.2242\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0832 - mae: 0.2286 - val_loss: 0.0824 - val_mae: 0.2242\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0778 - mae: 0.2206 - val_loss: 0.0699 - val_mae: 0.2128\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0778 - mae: 0.2206 - val_loss: 0.0699 - val_mae: 0.2128\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0756 - mae: 0.2193 - val_loss: 0.0726 - val_mae: 0.2129\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0756 - mae: 0.2193 - val_loss: 0.0726 - val_mae: 0.2129\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0634 - mae: 0.2009 - val_loss: 0.0577 - val_mae: 0.1903\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0634 - mae: 0.2009 - val_loss: 0.0577 - val_mae: 0.1903\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0601 - mae: 0.1933 - val_loss: 0.0733 - val_mae: 0.2170\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0601 - mae: 0.1933 - val_loss: 0.0733 - val_mae: 0.2170\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0611 - mae: 0.1953 - val_loss: 0.0651 - val_mae: 0.2019\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0611 - mae: 0.1953 - val_loss: 0.0651 - val_mae: 0.2019\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0568 - mae: 0.1890 - val_loss: 0.0817 - val_mae: 0.2253\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0568 - mae: 0.1890 - val_loss: 0.0817 - val_mae: 0.2253\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.1874 - val_loss: 0.0573 - val_mae: 0.1893\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.1874 - val_loss: 0.0573 - val_mae: 0.1893\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0561 - mae: 0.1885 - val_loss: 0.0536 - val_mae: 0.1803\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0561 - mae: 0.1885 - val_loss: 0.0536 - val_mae: 0.1803\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0493 - mae: 0.1777 - val_loss: 0.0668 - val_mae: 0.2039\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0493 - mae: 0.1777 - val_loss: 0.0668 - val_mae: 0.2039\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0499 - mae: 0.1764 - val_loss: 0.0626 - val_mae: 0.1993\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0499 - mae: 0.1764 - val_loss: 0.0626 - val_mae: 0.1993\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0502 - mae: 0.1787 - val_loss: 0.0468 - val_mae: 0.1685\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0502 - mae: 0.1787 - val_loss: 0.0468 - val_mae: 0.1685\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0484 - mae: 0.1764 - val_loss: 0.0505 - val_mae: 0.1760\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0484 - mae: 0.1764 - val_loss: 0.0505 - val_mae: 0.1760\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0499 - mae: 0.1771 - val_loss: 0.0470 - val_mae: 0.1708\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0499 - mae: 0.1771 - val_loss: 0.0470 - val_mae: 0.1708\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0462 - mae: 0.1686 - val_loss: 0.0494 - val_mae: 0.1756\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0462 - mae: 0.1686 - val_loss: 0.0494 - val_mae: 0.1756\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.1714 - val_loss: 0.0492 - val_mae: 0.1719\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0463 - mae: 0.1714 - val_loss: 0.0492 - val_mae: 0.1719\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0477 - mae: 0.1742 - val_loss: 0.0518 - val_mae: 0.1795\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0477 - mae: 0.1742 - val_loss: 0.0518 - val_mae: 0.1795\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0439 - mae: 0.1670 - val_loss: 0.0488 - val_mae: 0.1739\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0439 - mae: 0.1670 - val_loss: 0.0488 - val_mae: 0.1739\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0420 - mae: 0.1632 - val_loss: 0.0498 - val_mae: 0.1753\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0420 - mae: 0.1632 - val_loss: 0.0498 - val_mae: 0.1753\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - mae: 0.1652 - val_loss: 0.0513 - val_mae: 0.1781\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - mae: 0.1652 - val_loss: 0.0513 - val_mae: 0.1781\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0456 - mae: 0.1711 - val_loss: 0.0570 - val_mae: 0.1914\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0456 - mae: 0.1711 - val_loss: 0.0570 - val_mae: 0.1914\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0411 - mae: 0.1613 - val_loss: 0.0552 - val_mae: 0.1850\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0411 - mae: 0.1613 - val_loss: 0.0552 - val_mae: 0.1850\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0405 - mae: 0.1613 - val_loss: 0.0514 - val_mae: 0.1765\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0405 - mae: 0.1613 - val_loss: 0.0514 - val_mae: 0.1765\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0421 - mae: 0.1648 - val_loss: 0.0516 - val_mae: 0.1787\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0421 - mae: 0.1648 - val_loss: 0.0516 - val_mae: 0.1787\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0416 - mae: 0.1643 - val_loss: 0.0500 - val_mae: 0.1739\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0416 - mae: 0.1643 - val_loss: 0.0500 - val_mae: 0.1739\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.1600 - val_loss: 0.0460 - val_mae: 0.1683\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0397 - mae: 0.1600 - val_loss: 0.0460 - val_mae: 0.1683\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0413 - mae: 0.1640 - val_loss: 0.0476 - val_mae: 0.1706\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0413 - mae: 0.1640 - val_loss: 0.0476 - val_mae: 0.1706\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0428 - mae: 0.1657 - val_loss: 0.0489 - val_mae: 0.1752\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0428 - mae: 0.1657 - val_loss: 0.0489 - val_mae: 0.1752\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - mae: 0.1574 - val_loss: 0.0446 - val_mae: 0.1660\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0380 - mae: 0.1574 - val_loss: 0.0446 - val_mae: 0.1660\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.1575 - val_loss: 0.0463 - val_mae: 0.1682\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0391 - mae: 0.1575 - val_loss: 0.0463 - val_mae: 0.1682\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0408 - mae: 0.1611 - val_loss: 0.0560 - val_mae: 0.1894\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0408 - mae: 0.1611 - val_loss: 0.0560 - val_mae: 0.1894\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0374 - mae: 0.1531 - val_loss: 0.0465 - val_mae: 0.1710\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0374 - mae: 0.1531 - val_loss: 0.0465 - val_mae: 0.1710\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0366 - mae: 0.1520 - val_loss: 0.0462 - val_mae: 0.1661\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0366 - mae: 0.1520 - val_loss: 0.0462 - val_mae: 0.1661\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0358 - mae: 0.1516 - val_loss: 0.0547 - val_mae: 0.1870\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0358 - mae: 0.1516 - val_loss: 0.0547 - val_mae: 0.1870\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0401 - mae: 0.1588 - val_loss: 0.0525 - val_mae: 0.1817\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0401 - mae: 0.1588 - val_loss: 0.0525 - val_mae: 0.1817\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0429 - mae: 0.1668 - val_loss: 0.0496 - val_mae: 0.1762\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0429 - mae: 0.1668 - val_loss: 0.0496 - val_mae: 0.1762\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0384 - mae: 0.1573 - val_loss: 0.0481 - val_mae: 0.1719\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0384 - mae: 0.1573 - val_loss: 0.0481 - val_mae: 0.1719\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.1546 - val_loss: 0.0449 - val_mae: 0.1677\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0374 - mae: 0.1546 - val_loss: 0.0449 - val_mae: 0.1677\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.1471 - val_loss: 0.0489 - val_mae: 0.1726\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.1471 - val_loss: 0.0489 - val_mae: 0.1726\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.1500 - val_loss: 0.0461 - val_mae: 0.1677\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0357 - mae: 0.1500 - val_loss: 0.0461 - val_mae: 0.1677\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.1501 - val_loss: 0.0447 - val_mae: 0.1636\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.1501 - val_loss: 0.0447 - val_mae: 0.1636\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0366 - mae: 0.1533 - val_loss: 0.0512 - val_mae: 0.1792\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0366 - mae: 0.1533 - val_loss: 0.0512 - val_mae: 0.1792\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.1509 - val_loss: 0.0513 - val_mae: 0.1782\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0362 - mae: 0.1509 - val_loss: 0.0513 - val_mae: 0.1782\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.1491 - val_loss: 0.0424 - val_mae: 0.1612\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.1491 - val_loss: 0.0424 - val_mae: 0.1612\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mae: 0.1455 - val_loss: 0.0452 - val_mae: 0.1667\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0335 - mae: 0.1455 - val_loss: 0.0452 - val_mae: 0.1667\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0325 - mae: 0.1436 - val_loss: 0.0427 - val_mae: 0.1623\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0325 - mae: 0.1436 - val_loss: 0.0427 - val_mae: 0.1623\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1502 - val_loss: 0.0446 - val_mae: 0.1635\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1502 - val_loss: 0.0446 - val_mae: 0.1635\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model3 = Sequential()\n",
    "model3.add(Conv1D(64, kernel_size=2, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(50, activation='relu'))\n",
    "model3.add(Dense(1))  # linear output for regression\n",
    "# Your code here\n",
    "model3.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Fit the third model\n",
    "history3 = model3.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Test MSE: 0.04503756368444725, Test MAE: 0.16592758621392015\n",
      "Test MSE: 0.04503756368444725, Test MAE: 0.16592758621392015\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate the model\n",
    "y_pred = model3.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense + Dropout + Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:  A single Dense Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 3.5968 - mae: 1.6174 - val_loss: 3.5391 - val_mae: 1.5891\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 3.5968 - mae: 1.6174 - val_loss: 3.5391 - val_mae: 1.5891\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.3335 - mae: 1.5509 - val_loss: 3.1171 - val_mae: 1.4836\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.3335 - mae: 1.5509 - val_loss: 3.1171 - val_mae: 1.4836\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.9633 - mae: 1.4509 - val_loss: 2.6514 - val_mae: 1.3600\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.9633 - mae: 1.4509 - val_loss: 2.6514 - val_mae: 1.3600\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5258 - mae: 1.3244 - val_loss: 2.1276 - val_mae: 1.2035\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5258 - mae: 1.3244 - val_loss: 2.1276 - val_mae: 1.2035\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0377 - mae: 1.1758 - val_loss: 1.7103 - val_mae: 1.0494\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0377 - mae: 1.1758 - val_loss: 1.7103 - val_mae: 1.0494\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6346 - mae: 1.0344 - val_loss: 1.4084 - val_mae: 0.9166\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6346 - mae: 1.0344 - val_loss: 1.4084 - val_mae: 0.9166\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3444 - mae: 0.9150 - val_loss: 1.1678 - val_mae: 0.8199\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3444 - mae: 0.9150 - val_loss: 1.1678 - val_mae: 0.8199\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1035 - mae: 0.8125 - val_loss: 0.9510 - val_mae: 0.7403\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1035 - mae: 0.8125 - val_loss: 0.9510 - val_mae: 0.7403\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9083 - mae: 0.7285 - val_loss: 0.7747 - val_mae: 0.6675\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9083 - mae: 0.7285 - val_loss: 0.7747 - val_mae: 0.6675\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7460 - mae: 0.6525 - val_loss: 0.6102 - val_mae: 0.5945\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7460 - mae: 0.6525 - val_loss: 0.6102 - val_mae: 0.5945\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5902 - mae: 0.5763 - val_loss: 0.4622 - val_mae: 0.5136\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5902 - mae: 0.5763 - val_loss: 0.4622 - val_mae: 0.5136\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4318 - mae: 0.4887 - val_loss: 0.3301 - val_mae: 0.4284\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4318 - mae: 0.4887 - val_loss: 0.3301 - val_mae: 0.4284\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2888 - mae: 0.3998 - val_loss: 0.2147 - val_mae: 0.3441\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2888 - mae: 0.3998 - val_loss: 0.2147 - val_mae: 0.3441\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1770 - mae: 0.3155 - val_loss: 0.1308 - val_mae: 0.2731\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1770 - mae: 0.3155 - val_loss: 0.1308 - val_mae: 0.2731\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1039 - mae: 0.2484 - val_loss: 0.0785 - val_mae: 0.2202\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1039 - mae: 0.2484 - val_loss: 0.0785 - val_mae: 0.2202\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0649 - mae: 0.2035 - val_loss: 0.0542 - val_mae: 0.1884\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0649 - mae: 0.2035 - val_loss: 0.0542 - val_mae: 0.1884\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0477 - mae: 0.1767 - val_loss: 0.0434 - val_mae: 0.1702\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0477 - mae: 0.1767 - val_loss: 0.0434 - val_mae: 0.1702\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1645 - val_loss: 0.0388 - val_mae: 0.1614\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - mae: 0.1645 - val_loss: 0.0388 - val_mae: 0.1614\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1590 - val_loss: 0.0370 - val_mae: 0.1582\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - mae: 0.1590 - val_loss: 0.0370 - val_mae: 0.1582\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1561 - val_loss: 0.0364 - val_mae: 0.1572\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1561 - val_loss: 0.0364 - val_mae: 0.1572\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1554 - val_loss: 0.0360 - val_mae: 0.1566\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1554 - val_loss: 0.0360 - val_mae: 0.1566\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1553 - val_loss: 0.0360 - val_mae: 0.1567\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1553 - val_loss: 0.0360 - val_mae: 0.1567\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1552 - val_loss: 0.0359 - val_mae: 0.1566\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1552 - val_loss: 0.0359 - val_mae: 0.1566\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1562\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1562\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1554 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1554 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1553 - val_loss: 0.0362 - val_mae: 0.1568\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1553 - val_loss: 0.0362 - val_mae: 0.1568\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1553 - val_loss: 0.0361 - val_mae: 0.1566\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1553 - val_loss: 0.0361 - val_mae: 0.1566\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1550 - val_loss: 0.0358 - val_mae: 0.1561\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - mae: 0.1550 - val_loss: 0.0358 - val_mae: 0.1561\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1552 - val_loss: 0.0358 - val_mae: 0.1564\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1552 - val_loss: 0.0358 - val_mae: 0.1564\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1557 - val_loss: 0.0360 - val_mae: 0.1566\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1557 - val_loss: 0.0360 - val_mae: 0.1566\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1564\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1551 - val_loss: 0.0360 - val_mae: 0.1564\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1556 - val_loss: 0.0360 - val_mae: 0.1568\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - mae: 0.1556 - val_loss: 0.0360 - val_mae: 0.1568\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1552 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1552 - val_loss: 0.0360 - val_mae: 0.1565\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1556 - val_loss: 0.0363 - val_mae: 0.1570\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1556 - val_loss: 0.0363 - val_mae: 0.1570\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1551 - val_loss: 0.0357 - val_mae: 0.1561\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1551 - val_loss: 0.0357 - val_mae: 0.1561\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1557 - val_loss: 0.0361 - val_mae: 0.1565\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1557 - val_loss: 0.0361 - val_mae: 0.1565\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1555 - val_loss: 0.0360 - val_mae: 0.1559\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1555 - val_loss: 0.0360 - val_mae: 0.1559\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1558 - val_loss: 0.0361 - val_mae: 0.1567\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1558 - val_loss: 0.0361 - val_mae: 0.1567\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1556 - val_loss: 0.0361 - val_mae: 0.1564\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1556 - val_loss: 0.0361 - val_mae: 0.1564\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1554 - val_loss: 0.0368 - val_mae: 0.1577\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1554 - val_loss: 0.0368 - val_mae: 0.1577\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.1558 - val_loss: 0.0359 - val_mae: 0.1565\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - mae: 0.1558 - val_loss: 0.0359 - val_mae: 0.1565\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1553 - val_loss: 0.0363 - val_mae: 0.1571\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1553 - val_loss: 0.0363 - val_mae: 0.1571\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1558 - val_loss: 0.0361 - val_mae: 0.1565\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0368 - mae: 0.1558 - val_loss: 0.0361 - val_mae: 0.1565\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1554 - val_loss: 0.0358 - val_mae: 0.1566\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1554 - val_loss: 0.0358 - val_mae: 0.1566\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1549 - val_loss: 0.0361 - val_mae: 0.1570\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1549 - val_loss: 0.0361 - val_mae: 0.1570\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1560 - val_loss: 0.0359 - val_mae: 0.1561\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0369 - mae: 0.1560 - val_loss: 0.0359 - val_mae: 0.1561\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1556 - val_loss: 0.0360 - val_mae: 0.1567\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1556 - val_loss: 0.0360 - val_mae: 0.1567\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1554 - val_loss: 0.0362 - val_mae: 0.1568\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - mae: 0.1554 - val_loss: 0.0362 - val_mae: 0.1568\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Test MSE: 0.03586787191045064, Test MAE: 0.15055585052267886\n",
      "Test MSE: 0.03586787191045064, Test MAE: 0.15055585052267886\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Experiment 1:  A single Dense Hidden Layer\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: A set of three Dense Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6814 - mae: 0.5658 - val_loss: 0.1194 - val_mae: 0.2798\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6814 - mae: 0.5658 - val_loss: 0.1194 - val_mae: 0.2798\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0987 - mae: 0.2512 - val_loss: 0.0844 - val_mae: 0.2341\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0987 - mae: 0.2512 - val_loss: 0.0844 - val_mae: 0.2341\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0729 - mae: 0.2174 - val_loss: 0.0666 - val_mae: 0.2083\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0729 - mae: 0.2174 - val_loss: 0.0666 - val_mae: 0.2083\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0586 - mae: 0.1941 - val_loss: 0.0648 - val_mae: 0.2021\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0586 - mae: 0.1941 - val_loss: 0.0648 - val_mae: 0.2021\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0513 - mae: 0.1830 - val_loss: 0.0564 - val_mae: 0.1885\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0513 - mae: 0.1830 - val_loss: 0.0564 - val_mae: 0.1885\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0463 - mae: 0.1741 - val_loss: 0.0550 - val_mae: 0.1858\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0463 - mae: 0.1741 - val_loss: 0.0550 - val_mae: 0.1858\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0426 - mae: 0.1664 - val_loss: 0.0550 - val_mae: 0.1869\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0426 - mae: 0.1664 - val_loss: 0.0550 - val_mae: 0.1869\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - mae: 0.1615 - val_loss: 0.0536 - val_mae: 0.1871\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - mae: 0.1615 - val_loss: 0.0536 - val_mae: 0.1871\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1582 - val_loss: 0.0544 - val_mae: 0.1852\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1582 - val_loss: 0.0544 - val_mae: 0.1852\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1521 - val_loss: 0.0500 - val_mae: 0.1767\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1521 - val_loss: 0.0500 - val_mae: 0.1767\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1489 - val_loss: 0.0500 - val_mae: 0.1812\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1489 - val_loss: 0.0500 - val_mae: 0.1812\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.1448 - val_loss: 0.0477 - val_mae: 0.1759\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.1448 - val_loss: 0.0477 - val_mae: 0.1759\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - mae: 0.1387 - val_loss: 0.0489 - val_mae: 0.1766\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - mae: 0.1387 - val_loss: 0.0489 - val_mae: 0.1766\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - mae: 0.1385 - val_loss: 0.0502 - val_mae: 0.1778\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - mae: 0.1385 - val_loss: 0.0502 - val_mae: 0.1778\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0470 - val_mae: 0.1728\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0284 - mae: 0.1351 - val_loss: 0.0470 - val_mae: 0.1728\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1330 - val_loss: 0.0502 - val_mae: 0.1795\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1330 - val_loss: 0.0502 - val_mae: 0.1795\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - mae: 0.1281 - val_loss: 0.0486 - val_mae: 0.1741\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - mae: 0.1281 - val_loss: 0.0486 - val_mae: 0.1741\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.1286 - val_loss: 0.0475 - val_mae: 0.1716\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.1286 - val_loss: 0.0475 - val_mae: 0.1716\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1284 - val_loss: 0.0501 - val_mae: 0.1785\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1284 - val_loss: 0.0501 - val_mae: 0.1785\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.1245 - val_loss: 0.0484 - val_mae: 0.1748\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.1245 - val_loss: 0.0484 - val_mae: 0.1748\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.1225 - val_loss: 0.0478 - val_mae: 0.1746\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.1225 - val_loss: 0.0478 - val_mae: 0.1746\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.1233 - val_loss: 0.0554 - val_mae: 0.1851\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.1233 - val_loss: 0.0554 - val_mae: 0.1851\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.1192 - val_loss: 0.0479 - val_mae: 0.1730\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.1192 - val_loss: 0.0479 - val_mae: 0.1730\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.1185 - val_loss: 0.0486 - val_mae: 0.1750\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.1185 - val_loss: 0.0486 - val_mae: 0.1750\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.1158 - val_loss: 0.0485 - val_mae: 0.1728\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.1158 - val_loss: 0.0485 - val_mae: 0.1728\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.1157 - val_loss: 0.0466 - val_mae: 0.1744\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.1157 - val_loss: 0.0466 - val_mae: 0.1744\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.1112 - val_loss: 0.0450 - val_mae: 0.1683\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.1112 - val_loss: 0.0450 - val_mae: 0.1683\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0223 - mae: 0.1183 - val_loss: 0.0496 - val_mae: 0.1756\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0223 - mae: 0.1183 - val_loss: 0.0496 - val_mae: 0.1756\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.1085 - val_loss: 0.0463 - val_mae: 0.1727\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.1085 - val_loss: 0.0463 - val_mae: 0.1727\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.1068 - val_loss: 0.0501 - val_mae: 0.1797\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.1068 - val_loss: 0.0501 - val_mae: 0.1797\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.1081 - val_loss: 0.0476 - val_mae: 0.1715\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.1081 - val_loss: 0.0476 - val_mae: 0.1715\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.1083 - val_loss: 0.0462 - val_mae: 0.1726\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.1083 - val_loss: 0.0462 - val_mae: 0.1726\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.1051 - val_loss: 0.0479 - val_mae: 0.1767\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.1051 - val_loss: 0.0479 - val_mae: 0.1767\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.1069 - val_loss: 0.0481 - val_mae: 0.1774\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.1069 - val_loss: 0.0481 - val_mae: 0.1774\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.1034 - val_loss: 0.0465 - val_mae: 0.1716\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.1034 - val_loss: 0.0465 - val_mae: 0.1716\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.1026 - val_loss: 0.0492 - val_mae: 0.1775\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.1026 - val_loss: 0.0492 - val_mae: 0.1775\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.1004 - val_loss: 0.0508 - val_mae: 0.1794\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.1004 - val_loss: 0.0508 - val_mae: 0.1794\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0500 - val_mae: 0.1802\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0500 - val_mae: 0.1802\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0983 - val_loss: 0.0484 - val_mae: 0.1752\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0983 - val_loss: 0.0484 - val_mae: 0.1752\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0987 - val_loss: 0.0507 - val_mae: 0.1774\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0987 - val_loss: 0.0507 - val_mae: 0.1774\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0952 - val_loss: 0.0498 - val_mae: 0.1784\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0952 - val_loss: 0.0498 - val_mae: 0.1784\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0969 - val_loss: 0.0466 - val_mae: 0.1713\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0969 - val_loss: 0.0466 - val_mae: 0.1713\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0964 - val_loss: 0.0491 - val_mae: 0.1760\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0964 - val_loss: 0.0491 - val_mae: 0.1760\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0906 - val_loss: 0.0520 - val_mae: 0.1820\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0906 - val_loss: 0.0520 - val_mae: 0.1820\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0955 - val_loss: 0.0509 - val_mae: 0.1836\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0955 - val_loss: 0.0509 - val_mae: 0.1836\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0925 - val_loss: 0.0534 - val_mae: 0.1845\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0925 - val_loss: 0.0534 - val_mae: 0.1845\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0928 - val_loss: 0.0508 - val_mae: 0.1797\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0928 - val_loss: 0.0508 - val_mae: 0.1797\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0543 - val_mae: 0.1852\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0543 - val_mae: 0.1852\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0905 - val_loss: 0.0512 - val_mae: 0.1802\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0905 - val_loss: 0.0512 - val_mae: 0.1802\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0907 - val_loss: 0.0513 - val_mae: 0.1804\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0907 - val_loss: 0.0513 - val_mae: 0.1804\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Test MSE: 0.05953945101053976, Test MAE: 0.19388471993857648\n",
      "Test MSE: 0.05953945101053976, Test MAE: 0.19388471993857648\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create the model\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_2.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_2.add(Dense(1, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Run the model\n",
    "history = model_2.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model_2.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Add a dropout after each Dense Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4875 - mae: 0.9140 - val_loss: 0.4283 - val_mae: 0.5653\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1.4875 - mae: 0.9140 - val_loss: 0.4283 - val_mae: 0.5653\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2065 - mae: 0.7662 - val_loss: 0.3534 - val_mae: 0.5117\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2065 - mae: 0.7662 - val_loss: 0.3534 - val_mae: 0.5117\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0123 - mae: 0.6915 - val_loss: 0.3677 - val_mae: 0.5272\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0123 - mae: 0.6915 - val_loss: 0.3677 - val_mae: 0.5272\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9722 - mae: 0.6644 - val_loss: 0.3984 - val_mae: 0.5477\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9722 - mae: 0.6644 - val_loss: 0.3984 - val_mae: 0.5477\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1365 - mae: 0.6934 - val_loss: 0.4038 - val_mae: 0.5583\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1365 - mae: 0.6934 - val_loss: 0.4038 - val_mae: 0.5583\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0596 - mae: 0.6563 - val_loss: 0.3663 - val_mae: 0.5280\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0596 - mae: 0.6563 - val_loss: 0.3663 - val_mae: 0.5280\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0028 - mae: 0.6295 - val_loss: 0.3241 - val_mae: 0.4978\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0028 - mae: 0.6295 - val_loss: 0.3241 - val_mae: 0.4978\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1274 - mae: 0.6762 - val_loss: 0.2432 - val_mae: 0.4270\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1274 - mae: 0.6762 - val_loss: 0.2432 - val_mae: 0.4270\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9703 - mae: 0.6112 - val_loss: 0.2992 - val_mae: 0.4775\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9703 - mae: 0.6112 - val_loss: 0.2992 - val_mae: 0.4775\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9631 - mae: 0.5996 - val_loss: 0.2668 - val_mae: 0.4539\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9631 - mae: 0.5996 - val_loss: 0.2668 - val_mae: 0.4539\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0291 - mae: 0.6214 - val_loss: 0.3688 - val_mae: 0.5336\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0291 - mae: 0.6214 - val_loss: 0.3688 - val_mae: 0.5336\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9700 - mae: 0.5935 - val_loss: 0.2895 - val_mae: 0.4756\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9700 - mae: 0.5935 - val_loss: 0.2895 - val_mae: 0.4756\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9701 - mae: 0.5962 - val_loss: 0.3324 - val_mae: 0.5036\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9701 - mae: 0.5962 - val_loss: 0.3324 - val_mae: 0.5036\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9954 - mae: 0.5975 - val_loss: 0.2571 - val_mae: 0.4404\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9954 - mae: 0.5975 - val_loss: 0.2571 - val_mae: 0.4404\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0399 - mae: 0.6019 - val_loss: 0.3089 - val_mae: 0.4845\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0399 - mae: 0.6019 - val_loss: 0.3089 - val_mae: 0.4845\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8330 - mae: 0.5481 - val_loss: 0.2513 - val_mae: 0.4376\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8330 - mae: 0.5481 - val_loss: 0.2513 - val_mae: 0.4376\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9855 - mae: 0.5888 - val_loss: 0.2886 - val_mae: 0.4665\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9855 - mae: 0.5888 - val_loss: 0.2886 - val_mae: 0.4665\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9120 - mae: 0.5548 - val_loss: 0.3541 - val_mae: 0.5209\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9120 - mae: 0.5548 - val_loss: 0.3541 - val_mae: 0.5209\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8973 - mae: 0.5456 - val_loss: 0.2872 - val_mae: 0.4628\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8973 - mae: 0.5456 - val_loss: 0.2872 - val_mae: 0.4628\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9856 - mae: 0.5704 - val_loss: 0.2664 - val_mae: 0.4494\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9856 - mae: 0.5704 - val_loss: 0.2664 - val_mae: 0.4494\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0219 - mae: 0.5820 - val_loss: 0.3150 - val_mae: 0.4837\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0219 - mae: 0.5820 - val_loss: 0.3150 - val_mae: 0.4837\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0497 - mae: 0.5879 - val_loss: 0.3467 - val_mae: 0.5089\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0497 - mae: 0.5879 - val_loss: 0.3467 - val_mae: 0.5089\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9745 - mae: 0.5687 - val_loss: 0.2869 - val_mae: 0.4641\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9745 - mae: 0.5687 - val_loss: 0.2869 - val_mae: 0.4641\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0256 - mae: 0.5800 - val_loss: 0.2411 - val_mae: 0.4224\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0256 - mae: 0.5800 - val_loss: 0.2411 - val_mae: 0.4224\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9976 - mae: 0.5708 - val_loss: 0.2517 - val_mae: 0.4370\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9976 - mae: 0.5708 - val_loss: 0.2517 - val_mae: 0.4370\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9254 - mae: 0.5505 - val_loss: 0.2934 - val_mae: 0.4700\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9254 - mae: 0.5505 - val_loss: 0.2934 - val_mae: 0.4700\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9166 - mae: 0.5435 - val_loss: 0.3297 - val_mae: 0.5012\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9166 - mae: 0.5435 - val_loss: 0.3297 - val_mae: 0.5012\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9305 - mae: 0.5399 - val_loss: 0.2101 - val_mae: 0.3987\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9305 - mae: 0.5399 - val_loss: 0.2101 - val_mae: 0.3987\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8603 - mae: 0.5158 - val_loss: 0.2757 - val_mae: 0.4555\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8603 - mae: 0.5158 - val_loss: 0.2757 - val_mae: 0.4555\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8047 - mae: 0.4960 - val_loss: 0.2508 - val_mae: 0.4327\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8047 - mae: 0.4960 - val_loss: 0.2508 - val_mae: 0.4327\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9361 - mae: 0.5505 - val_loss: 0.2227 - val_mae: 0.4103\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9361 - mae: 0.5505 - val_loss: 0.2227 - val_mae: 0.4103\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9006 - mae: 0.5293 - val_loss: 0.2692 - val_mae: 0.4506\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9006 - mae: 0.5293 - val_loss: 0.2692 - val_mae: 0.4506\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9881 - mae: 0.5521 - val_loss: 0.2481 - val_mae: 0.4326\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9881 - mae: 0.5521 - val_loss: 0.2481 - val_mae: 0.4326\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9257 - mae: 0.5313 - val_loss: 0.2384 - val_mae: 0.4272\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9257 - mae: 0.5313 - val_loss: 0.2384 - val_mae: 0.4272\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9724 - mae: 0.5566 - val_loss: 0.2803 - val_mae: 0.4577\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9724 - mae: 0.5566 - val_loss: 0.2803 - val_mae: 0.4577\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8721 - mae: 0.5143 - val_loss: 0.2655 - val_mae: 0.4450\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8721 - mae: 0.5143 - val_loss: 0.2655 - val_mae: 0.4450\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0006 - mae: 0.5649 - val_loss: 0.2019 - val_mae: 0.3889\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0006 - mae: 0.5649 - val_loss: 0.2019 - val_mae: 0.3889\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9303 - mae: 0.5344 - val_loss: 0.2681 - val_mae: 0.4465\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9303 - mae: 0.5344 - val_loss: 0.2681 - val_mae: 0.4465\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8497 - mae: 0.5046 - val_loss: 0.2423 - val_mae: 0.4242\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8497 - mae: 0.5046 - val_loss: 0.2423 - val_mae: 0.4242\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8867 - mae: 0.5205 - val_loss: 0.3454 - val_mae: 0.5030\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8867 - mae: 0.5205 - val_loss: 0.3454 - val_mae: 0.5030\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9186 - mae: 0.5301 - val_loss: 0.2315 - val_mae: 0.4158\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9186 - mae: 0.5301 - val_loss: 0.2315 - val_mae: 0.4158\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9590 - mae: 0.5442 - val_loss: 0.2368 - val_mae: 0.4203\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9590 - mae: 0.5442 - val_loss: 0.2368 - val_mae: 0.4203\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8493 - mae: 0.5044 - val_loss: 0.2412 - val_mae: 0.4227\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8493 - mae: 0.5044 - val_loss: 0.2412 - val_mae: 0.4227\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8398 - mae: 0.5036 - val_loss: 0.2426 - val_mae: 0.4240\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8398 - mae: 0.5036 - val_loss: 0.2426 - val_mae: 0.4240\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9578 - mae: 0.5448 - val_loss: 0.2358 - val_mae: 0.4188\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9578 - mae: 0.5448 - val_loss: 0.2358 - val_mae: 0.4188\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9486 - mae: 0.5363 - val_loss: 0.2499 - val_mae: 0.4301\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9486 - mae: 0.5363 - val_loss: 0.2499 - val_mae: 0.4301\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9428 - mae: 0.5245 - val_loss: 0.2572 - val_mae: 0.4368\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9428 - mae: 0.5245 - val_loss: 0.2572 - val_mae: 0.4368\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9654 - mae: 0.5380 - val_loss: 0.2509 - val_mae: 0.4298\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9654 - mae: 0.5380 - val_loss: 0.2509 - val_mae: 0.4298\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8599 - mae: 0.5053 - val_loss: 0.2726 - val_mae: 0.4491\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8599 - mae: 0.5053 - val_loss: 0.2726 - val_mae: 0.4491\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8559 - mae: 0.5034 - val_loss: 0.2637 - val_mae: 0.4426\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8559 - mae: 0.5034 - val_loss: 0.2637 - val_mae: 0.4426\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Test MSE: 0.257353465684118, Test MAE: 0.43887318215154636\n",
      "Test MSE: 0.257353465684118, Test MAE: 0.43887318215154636\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Create the model\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(1, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_3.add(Dropout(0.2))\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Run the model\n",
    "history = model_3.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model_3.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Add a Batch Normalization Layer after each Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pansocrates03\\Documents\\7mo Semestre\\DEEP LEARNING\\act3\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2.1202 - mae: 1.2000 - val_loss: 0.6221 - val_mae: 0.6370\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 2.1202 - mae: 1.2000 - val_loss: 0.6221 - val_mae: 0.6370\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1017 - mae: 0.8753 - val_loss: 0.3842 - val_mae: 0.4696\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1017 - mae: 0.8753 - val_loss: 0.3842 - val_mae: 0.4696\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8840 - mae: 0.7676 - val_loss: 0.3372 - val_mae: 0.4451\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8840 - mae: 0.7676 - val_loss: 0.3372 - val_mae: 0.4451\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6921 - mae: 0.6675 - val_loss: 0.2621 - val_mae: 0.4000\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6921 - mae: 0.6675 - val_loss: 0.2621 - val_mae: 0.4000\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6012 - mae: 0.6212 - val_loss: 0.1932 - val_mae: 0.3516\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6012 - mae: 0.6212 - val_loss: 0.1932 - val_mae: 0.3516\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5010 - mae: 0.5634 - val_loss: 0.1706 - val_mae: 0.3295\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5010 - mae: 0.5634 - val_loss: 0.1706 - val_mae: 0.3295\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4394 - mae: 0.5275 - val_loss: 0.1227 - val_mae: 0.2809\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4394 - mae: 0.5275 - val_loss: 0.1227 - val_mae: 0.2809\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3653 - mae: 0.4782 - val_loss: 0.1111 - val_mae: 0.2615\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3653 - mae: 0.4782 - val_loss: 0.1111 - val_mae: 0.2615\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3452 - mae: 0.4715 - val_loss: 0.0989 - val_mae: 0.2463\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3452 - mae: 0.4715 - val_loss: 0.0989 - val_mae: 0.2463\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3148 - mae: 0.4444 - val_loss: 0.0947 - val_mae: 0.2418\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3148 - mae: 0.4444 - val_loss: 0.0947 - val_mae: 0.2418\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2829 - mae: 0.4201 - val_loss: 0.0833 - val_mae: 0.2269\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2829 - mae: 0.4201 - val_loss: 0.0833 - val_mae: 0.2269\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2975 - mae: 0.4350 - val_loss: 0.0759 - val_mae: 0.2144\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2975 - mae: 0.4350 - val_loss: 0.0759 - val_mae: 0.2144\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2802 - mae: 0.4153 - val_loss: 0.0679 - val_mae: 0.1986\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2802 - mae: 0.4153 - val_loss: 0.0679 - val_mae: 0.1986\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2347 - mae: 0.3857 - val_loss: 0.0635 - val_mae: 0.1957\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2347 - mae: 0.3857 - val_loss: 0.0635 - val_mae: 0.1957\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2312 - mae: 0.3792 - val_loss: 0.0598 - val_mae: 0.1879\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2312 - mae: 0.3792 - val_loss: 0.0598 - val_mae: 0.1879\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2058 - mae: 0.3586 - val_loss: 0.0518 - val_mae: 0.1751\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2058 - mae: 0.3586 - val_loss: 0.0518 - val_mae: 0.1751\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1961 - mae: 0.3580 - val_loss: 0.0560 - val_mae: 0.1805\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1961 - mae: 0.3580 - val_loss: 0.0560 - val_mae: 0.1805\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2121 - mae: 0.3637 - val_loss: 0.0521 - val_mae: 0.1813\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2121 - mae: 0.3637 - val_loss: 0.0521 - val_mae: 0.1813\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2095 - mae: 0.3634 - val_loss: 0.0585 - val_mae: 0.1956\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2095 - mae: 0.3634 - val_loss: 0.0585 - val_mae: 0.1956\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1990 - mae: 0.3505 - val_loss: 0.0475 - val_mae: 0.1667\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1990 - mae: 0.3505 - val_loss: 0.0475 - val_mae: 0.1667\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1947 - mae: 0.3487 - val_loss: 0.0463 - val_mae: 0.1684\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1947 - mae: 0.3487 - val_loss: 0.0463 - val_mae: 0.1684\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1871 - mae: 0.3393 - val_loss: 0.0466 - val_mae: 0.1645\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1871 - mae: 0.3393 - val_loss: 0.0466 - val_mae: 0.1645\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1874 - mae: 0.3489 - val_loss: 0.0482 - val_mae: 0.1742\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1874 - mae: 0.3489 - val_loss: 0.0482 - val_mae: 0.1742\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1770 - mae: 0.3301 - val_loss: 0.0452 - val_mae: 0.1655\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1770 - mae: 0.3301 - val_loss: 0.0452 - val_mae: 0.1655\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1760 - mae: 0.3340 - val_loss: 0.0455 - val_mae: 0.1611\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1760 - mae: 0.3340 - val_loss: 0.0455 - val_mae: 0.1611\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1751 - mae: 0.3335 - val_loss: 0.0438 - val_mae: 0.1657\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1751 - mae: 0.3335 - val_loss: 0.0438 - val_mae: 0.1657\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2006 - mae: 0.3581 - val_loss: 0.0410 - val_mae: 0.1580\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2006 - mae: 0.3581 - val_loss: 0.0410 - val_mae: 0.1580\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1808 - mae: 0.3349 - val_loss: 0.0441 - val_mae: 0.1666\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1808 - mae: 0.3349 - val_loss: 0.0441 - val_mae: 0.1666\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1734 - mae: 0.3322 - val_loss: 0.0451 - val_mae: 0.1682\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1734 - mae: 0.3322 - val_loss: 0.0451 - val_mae: 0.1682\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1611 - mae: 0.3185 - val_loss: 0.0417 - val_mae: 0.1586\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1611 - mae: 0.3185 - val_loss: 0.0417 - val_mae: 0.1586\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1608 - mae: 0.3219 - val_loss: 0.0407 - val_mae: 0.1578\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1608 - mae: 0.3219 - val_loss: 0.0407 - val_mae: 0.1578\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1751 - mae: 0.3295 - val_loss: 0.0480 - val_mae: 0.1746\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1751 - mae: 0.3295 - val_loss: 0.0480 - val_mae: 0.1746\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1581 - mae: 0.3118 - val_loss: 0.0409 - val_mae: 0.1583\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1581 - mae: 0.3118 - val_loss: 0.0409 - val_mae: 0.1583\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1519 - mae: 0.3085 - val_loss: 0.0389 - val_mae: 0.1518\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1519 - mae: 0.3085 - val_loss: 0.0389 - val_mae: 0.1518\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1865 - mae: 0.3423 - val_loss: 0.0397 - val_mae: 0.1535\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1865 - mae: 0.3423 - val_loss: 0.0397 - val_mae: 0.1535\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1603 - mae: 0.3186 - val_loss: 0.0381 - val_mae: 0.1495\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1603 - mae: 0.3186 - val_loss: 0.0381 - val_mae: 0.1495\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1712 - mae: 0.3232 - val_loss: 0.0388 - val_mae: 0.1527\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1712 - mae: 0.3232 - val_loss: 0.0388 - val_mae: 0.1527\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1650 - mae: 0.3267 - val_loss: 0.0378 - val_mae: 0.1499\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1650 - mae: 0.3267 - val_loss: 0.0378 - val_mae: 0.1499\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1641 - mae: 0.3211 - val_loss: 0.0450 - val_mae: 0.1670\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1641 - mae: 0.3211 - val_loss: 0.0450 - val_mae: 0.1670\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1506 - mae: 0.3106 - val_loss: 0.0394 - val_mae: 0.1537\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1506 - mae: 0.3106 - val_loss: 0.0394 - val_mae: 0.1537\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1633 - mae: 0.3170 - val_loss: 0.0384 - val_mae: 0.1530\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1633 - mae: 0.3170 - val_loss: 0.0384 - val_mae: 0.1530\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1748 - mae: 0.3309 - val_loss: 0.0414 - val_mae: 0.1576\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1748 - mae: 0.3309 - val_loss: 0.0414 - val_mae: 0.1576\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1626 - mae: 0.3239 - val_loss: 0.0373 - val_mae: 0.1494\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1626 - mae: 0.3239 - val_loss: 0.0373 - val_mae: 0.1494\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1723 - mae: 0.3300 - val_loss: 0.0382 - val_mae: 0.1510\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1723 - mae: 0.3300 - val_loss: 0.0382 - val_mae: 0.1510\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1547 - mae: 0.3145 - val_loss: 0.0399 - val_mae: 0.1530\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1547 - mae: 0.3145 - val_loss: 0.0399 - val_mae: 0.1530\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1653 - mae: 0.3265 - val_loss: 0.0387 - val_mae: 0.1516\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1653 - mae: 0.3265 - val_loss: 0.0387 - val_mae: 0.1516\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1794 - mae: 0.3351 - val_loss: 0.0410 - val_mae: 0.1570\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1794 - mae: 0.3351 - val_loss: 0.0410 - val_mae: 0.1570\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1687 - mae: 0.3257 - val_loss: 0.0385 - val_mae: 0.1528\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1687 - mae: 0.3257 - val_loss: 0.0385 - val_mae: 0.1528\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1553 - mae: 0.3104 - val_loss: 0.0462 - val_mae: 0.1664\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1553 - mae: 0.3104 - val_loss: 0.0462 - val_mae: 0.1664\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1599 - mae: 0.3137 - val_loss: 0.0385 - val_mae: 0.1526\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1599 - mae: 0.3137 - val_loss: 0.0385 - val_mae: 0.1526\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Test MSE: 0.257353465684118, Test MAE: 0.43887318215154636\n",
      "Test MSE: 0.257353465684118, Test MAE: 0.43887318215154636\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Create the model\n",
    "model_4 = Sequential()\n",
    "model_4.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model_4.add(Dropout(0.2))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dense(1, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "\n",
    "# Compile the model\n",
    "model_4.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Run the model\n",
    "history = model_4.fit(x_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model_3.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Test MSE: {mse}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "Comparative results:\n",
      "Comparative results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Params</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experiment 1</td>\n",
       "      <td>0.035868</td>\n",
       "      <td>0.150556</td>\n",
       "      <td>14</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experiment 4</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.156465</td>\n",
       "      <td>3393</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Experiment 2</td>\n",
       "      <td>0.059539</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>3009</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Experiment 3</td>\n",
       "      <td>0.257353</td>\n",
       "      <td>0.438873</td>\n",
       "      <td>3009</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Experiment  Test MSE  Test MAE  Params Status\n",
       "0  Experiment 1  0.035868  0.150556      14     OK\n",
       "3  Experiment 4  0.039956  0.156465    3393     OK\n",
       "1  Experiment 2  0.059539  0.193885    3009     OK\n",
       "2  Experiment 3  0.257353  0.438873    3009     OK"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparative evaluation for Experiment 1-4\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "results = []\n",
    "models = {\n",
    "    'Experiment 1': globals().get('model'),\n",
    "    'Experiment 2': globals().get('model_2'),\n",
    "    'Experiment 3': globals().get('model_3'),\n",
    "    'Experiment 4': globals().get('model_4'),\n",
    "}\n",
    "\n",
    "for name, m in models.items():\n",
    "    if m is None:\n",
    "        results.append({'Experiment': name, 'Test MSE': None, 'Test MAE': None, 'Params': None, 'Status': 'Model not defined'})\n",
    "        continue\n",
    "    try:\n",
    "        # Some models (like Conv1D) may expect 3D input; try to reshape if needed\n",
    "        x_test_in = x_test\n",
    "        if len(m.input_shape) == 3 and x_test.ndim == 2:\n",
    "            # reshape to (samples, timesteps, features) where timesteps=features and features=1\n",
    "            x_test_in = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "        y_pred = m.predict(x_test_in)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        params = m.count_params()\n",
    "        results.append({'Experiment': name, 'Test MSE': mse, 'Test MAE': mae, 'Params': params, 'Status': 'OK'})\n",
    "    except Exception as e:\n",
    "        results.append({'Experiment': name, 'Test MSE': None, 'Test MAE': None, 'Params': getattr(m, 'count_params', lambda: None)(), 'Status': f'Error: {str(e)}'})\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "# Sort by Test MAE ascending when available\n",
    "df_results_sorted = df_results.sort_values(by=['Test MAE'], na_position='last')\n",
    "\n",
    "print('Comparative results:')\n",
    "\n",
    "display(df_results_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
