---
title: "Untitled"
author: "Esteban Sierra"
date: "2025-09-30"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
D = read.csv('AlCorte.csv')
```

# An√°lisis Descriptivo

Obtener el m√≠nimo, la mediana la media y otros valores
```{r}
n = 5 #n√∫mero de variables
d = matrix(NA,ncol=8,nrow=n)
for(i in 1:n){
  d[i,]<-c(as.numeric(summary(D[,i])), sd(D[ ,i]), sd(D[ ,i])/mean(D[ ,i]))
}
m = as.data.frame(d)
variables = names(D)
row.names(m) = variables
names(m) = c("Minimo","Q1","Mediana","Media","Q3","M√°ximo","Desv Est", "CV")
round(m,2)
```
Obtener la correlaci√≥n de las variables
```{r}
cor(D)
```
Obtener el gr√°fico de bigote
```{r}
colores = rainbow(5)
par(mfrow=c(1,5), las=1)
boxplot(D[1], col=colores[1], ylab=variables[1])
boxplot(D[2], col=colores[2], ylab=variables[2])
boxplot(D[3], col=colores[3], ylab=variables[3])
boxplot(D[4], col=colores[4], ylab=variables[4])
boxplot(D[5], col=colores[5], ylab=variables[5])

```

# Obtener mejor modelo de regresi√≥n

## Criterio AIC
```{r}
R = lm(Resistencia ~ . , data = D)
step(R, direction="both", trace=1)
```

## Criterio BIC
```{r}
n = length(D)
R = lm(Resistencia ~ . , data = D)
step(R, direction="both", k=log(n))
extractAIC(R, k=log(n))
```

## Criterio HQC
```{r}
HQC = step(R, direction="both", k=2*log(log(n)))
```
## Significancia
```{r}
BestModel = lm(Resistencia ~ Fuerza + Potencia + Temperatura, data = D)
summary(BestModel)
# Econom√≠a de las variables
#Significaci√≥n global (Prueba para el modelo)
#Significaci√≥n individual (Prueba para cada ùõΩùëñ)
#Variaci√≥n explicada por el modelo
```
### Econom√≠a de las variables


### Significancia global
La significancia global en este modelo es alta ya que el p-value es menor a 0.05.

### Significancia individual
El modelo tiene una alta significancia porque 
- Potencia: t = 7.033 y valor p casi cero
‚Äì Temperatura: t = 3.050 y valor p = 0.00499 

### Variaci√≥n explicada por el modelo
```{r}
confint(BestModel)
```


# An√°lisis de validez del modelo encontrado
## An√°lisis de residuos
### Homocedasticidad
### Independencia



# A1 Regresi√≥n m√∫ltiple

1. Haz un an√°lisis descriptivo de los datos: medidas principales y gr√°ficos
2. Encuentra el mejor modelo de regresi√≥n que explique la variable Resistencia. Analiza el modelo bas√°ndote en:
  1. Significancia del modelo:
    1. Econom√≠a de las variables
    2. Significaci√≥n global (Prueba para el modelo)
    3. Significaci√≥n individual (Prueba para cada ùõΩùëñ)
    4. Variaci√≥n explicada por el modelo
3. Analiza la validez del modelo encontrado:
  1. An√°lisis de residuos (homocedasticidad, independencia, etc)
  2. No multicolinealidad de Xi
4. Emite conclusiones sobre el modelo final encontrado e interpreta en el contexto del problema el efecto de las variables predictoras en la variable respuesta

# A3-Regresi√≥n M√∫ltiple-Detecci√≥n datos at√≠picos

1. Haz un an√°lisis descriptivo de los datos: medidas principales y gr√°ficos (ya lo hiciste en la actividad A2)
2. Encuentra el mejor modelo de regresi√≥n que explique la variable Resistencia (ya lo hiciste en la actividad A2) 
3. Analiza la validez del modelo encontrado (ya lo hiciste en la actividad A2)
4. Haz el an√°lisis de datos at√≠picos e incluyentes del mejor modelo encontrado.


## Datos at√≠picos o con alto leverage.
Comenta todos los datos at√≠picos o con alto leverage que encuentres. Comenta por qu√© son influyentes o no lo son seg√∫n el caso.


Matriz sombrero:
```{r}
leverage = hatvalues(BestModel)
plot(leverage, type="h", main="Valores de Apalancamiento", ylab="Apalancamiento")
abline(h = 2*mean(leverage), col="red") # L√≠mite com√∫nmente usado

high_leverage_points = which(leverage > 2*mean(leverage))
D[high_leverage_points, ]
```

Detecci√≥n de datos influyentes
```{r}
# Distancia de cook
#cooks.distance(BestModel)
#I = influence.measures(BestModel)
#summary(I)

cooksdistance <- cooks.distance(BestModel)
plot(cooksdistance, type="h", main="Distancia de Cook", ylab="Distancia de Cook")
abline(h = 1, col="red")

puntos_influyentes = which(cooksdistance > 1)

D[puntos_influyentes, ]

```

Se detectan DfBetas mayores a |1|
```{r}
dfbetas_values = dfbetas(BestModel)
#Calcula la DfBeta de los n datos para cada ùõΩùëó
#Gr√°fico auxiliar, para la variable 2:
plot(dfbetas_values[, 2], type="h", main="DfBetas para el coeficiente 2", ylab="DfBetas")
abline(h = c(-1, 1), col="red") # L√≠mites comunes
#Cuenta e identifica cu√°ntos datos at√≠picos hay:
puntos_influyentes = which(abs(dfbetas_values[, 2]) > 1)
```
